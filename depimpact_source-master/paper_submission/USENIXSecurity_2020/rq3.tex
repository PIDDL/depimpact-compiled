
%\input{tables/uniformLibraryReputation.tex}
\input{tables/usenix/RQ3rank}

\subsubsection{RQ3: Entry Node Ranking}
\label{subsubsec:rq3}

As shown in RQ2, the selection of entry nodes for forward causality analysis is critical in graph reduction.
Thus, in this RQ, we aim to measure whether the ground-true sources are among the top-ranked entry nodes produced by \tool.
We also compare \tool with another weight-computation approach (average-projection) and the random selection adopted by the monkey approach.
The difference between \tool and the average-projection approach is the parameter used to normalize the purposed features to the projection vector. 
For the average-projection approach, we manually select a set of fixed parameters (0.334, 0.333, 0.333) for the projection-vector normalization. 
Both \tool and the average-projection approach adopt the same relevance propagation method. 
After the relevance propagation, we rank entry nodes based on the relevance score. 
Ideally, the entry nodes relevant to the attack are expected to be ranked at the top. Based on the ground truth, we compute the average ranking of the attack-relevant entry nodes for these three approaches, as shown in~\cref{tab:rq3}. 
We can clearly see that \tool achieves the best average rank. 
Compared with the average-projection approach and the monkey approach, \tool achieves $29.34\%$ and $99.92\%$ improvement in relevance ranking.

Based on these results, we can conclude that \tool can provide a reasonable ranking list of entry nodes for forward causality analysis, with ground-true sources being ranked at 3.13 on average. These results provide the foundation for \tool to generate a small but attack-information-preserving subgraph.

\eat{
\label{subsubsec:reputationeval}
In previous evaluations, 
we have demonstrated the effectiveness of \tool when the reputations of entry nodes are well separated. 
Next, we would like to see how resilient \tool is when the reputation of entry nodes is mutated intentionally by attackers or unintentionally by mistake. 
Thus, we run the experiments on all the cases under two new reputation schemes:
(1) \textbf{Uniform Library}: assigning the reputation of a library node using a uniform random value in $\lbrack 0.2, 0.8\rbrack$, \ie making some of them malicious and some of them benign,
and keeping other nodes unchanged;
(2) \textbf{Uniform All}: besides shuffling the reputation uniformly for libraries, assigning the reputation of a trusted source using a uniform random value in $\lbrack 0.8, 1.0\rbrack$, and using $\lbrack 0.0, 0.2\rbrack$ for a untrusted source, respectively.

\cref{tab:diffSeedReputation} shows the results of the two schemes.
Note that to easily compute the average, for the real attack cases (marked with $*$), we convert the POI reputation $p$ to $1 - p$, so it will be shown as close to 1 when it is actually close to 0.
As we can see, in the Uniform Library scheme, for all cases, the POI reputation is close to $1.0$, indicating that even with the noise introduced in the libraries, the edge weights of \tool prevents the adverse impact on the POI reputation. 
In the Uniform All scheme, the POI reputations of some cases have obvious changes (\eg mal\_script, python\_wget, shell\_wget \textit{etc.}). 
Column \textit{Avg. Non-Lib} shows the average reputation of non-lib entry nodes representing trusted or suspicious sources. The Pearson correlation between the reputations of the POI and the non-lib entry nodes is $0.885$, indicating a strong correlation.

These results indicate that \tool is resilient to mutations on the library reputation and the POI reputation is strongly correlated with non-lib entry nodes.
In real world scenarios,
it will be relatively easy for the attacker to perturb the reputation for libraries given the massive number of libraries to keep track of. 
Also, since there are a few non-lib entry nodes in each attack and security analysts will be asked to inspect them, it will be more difficult for the attacker to mutate the reputation without being noticed.
If the attacker succeeds in tricking the security analysts in trusting a suspicious source, the security analyst will misclassify the attack since in the end the security analyst will determine whether it forms an attack based on the source,
no matter \tool is used or not.
}


