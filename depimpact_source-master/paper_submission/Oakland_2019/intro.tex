\section{Introduction}
 Advanced Persistent Threat (APT) attacks~\cite{fireeye:anatomy,aptsymantec} have caused many well-protected companies with significant financial losses~\cite{ebay,opm,target,homedepot,ya:yahooleak}.
These APT attacks often infiltrate into target systems in multiple stages 
and span a long duration of time with a low profile, posing challenges for detection and investigation.
Thus, enterprises have a strong need for solutions that can unfold these attacks for identifying root causes and ramifications,
which is critical to perform system recovery in a timely manner and prevent future compromises.

Causality analysis~\cite{backtracking,backtracking2,wormlog,logtracking,mcitracking} has emerged as an important solution for investigation of APT attacks. It is built upon \emph{ubiquitous system monitoring} that collects system level auditing events about system calls.
Causal analysis assumes causal dependencies between system entities (\eg processes) and system resources (\eg files and network sockets) involved in the same system call event (\eg a process reading a file),
and organizes these system call events as a \emph{dependency graph}, where nodes represent system entities/resources, edges represent dependency among the nodes, and the direction of the edges represent data flow.
By inspecting such a dependency graph, security analysts can trace back POI (Point-Of-Interest) events to identify the entry point of the attacks and understand the damages of the attacks. 
For example, when an attacker exploits vulnerabilities for installing and executing malicious payloads, the dependency graph generated by causality analysis can reveal such vulnerable interfaces that accept malicious inputs from the network.
Such capability is particularly important in attack investigation, since the causality of malicious events reveal the attack provenance.

However, there are two major limitations of causality analysis.
First, causality analysis suffers from dependency explosion~\cite{depexplosion,timelytrack}.
For example, a long-running process that accepts many inputs (\eg a web browser or a file manager) can cause its output events (\eg writing to a file) to have dependencies on all the preceding input events.
As such, the generated dependency graph for a suspicious downloaded file often consists of hundreds or even thousands of nodes and tens of thousands of edges,
and the \emph{critical edges} that reveal the attack provenance are buried in a huge number of irrelevant edges.
Second, while a dependency graph already significantly reduces the efforts in revealing the attack provenance, the inspection of the graph is still a labor-intensive work for the security analysts, especially when the graph size is often large.
Thus, it is a daunting task for the security analysts to inspect dependency graphs manually and identify the critical edges.


Existing works have mainly focused on addressing the dependency explosion problem via data reduction~\cite{backtracking,backtracking2,taser,intrusionrecovery}.
In particular, these works propose to remove irrelevant dependencies via (i) heuristically pruning specific files~\cite{backtracking,backtracking2}, (ii) collecting enhanced run-time information through binary instrumentation~\cite{mcitracking,loggc}, customized kernel~\cite{trustkernel}, and taint analysis~\cite{ma2016protracer}, or (iii) prioritizing dependencies using reference models of normal activities~\cite{timelytrack}.
However, heuristics often cause the loss of important dependencies~\cite{backtracking,reduction}; 
changing end-user systems, such as instrumentation and customization on kernel, are not practical in many organizations such as industry or government;
and reference models are difficult to control and they cannot be easily generalized from one organization to the other.
Furthermore, none of these works provide tool support for the inspection of the output graph,
and they still require non-trivial manual efforts to reveal the attack provenance. 

In this paper, we propose a weighted causality analysis approach, \tool, which (i) assigns weights to edges in the dependency graph for surfacing critical edges,
and (ii) propagates reputation values on the weighted dependency graph to automatically determine whether the system entities involved in the POI events have similar reputations as the trusted sources (\eg verified binaries and trusted websites) or malicious sources (\eg USB sticks or unknown IPs). 
To address dependency explosion, \tool allows security analysts to hide non-critical edges without pruning critical edges by adjusting a threshold values within the suggested range.
To provide tool support for automatic inspection of dependency graph, the reputation propagation of \tool can automatically determine whether the POI events in the dependency graph are malicious payloads (\eg executable files coming from malicious tools or suspicious websites) or benign entities (\eg files produced by trusted processes). 

There are two key insights of \tool.
First, given a dependency graph of a POI event, its critical edges often possess different properties than non-critical edges that are unlikely to reveal attack provenance.
For example, critical edges often read or write some files with the data amounts close to the file involved in the POI event (referred to as \emph{target file}), and the time stamps associated with these edges are quite close to the time stamp of the POI event. 

Based on this insight, \tool extracts three novel types of discriminative features from a system auditing event: (i) \textbf{relative data amount difference} that measures the distance between the number of bytes of data processed by the system call (\eg read 1k bytes) and the target file's size;
(ii) \textbf{relative time difference} that measures the distance of the time stamps between a dependency event and the POI event; 
(iii) \textbf{concentration degree} that measures the ratio of incoming edges over outgoing edges for a system entity, which is particularly useful for smoothing out the impacts of libraries with no incoming edges and long-running processes with many outgoing edges.
Based on these features, \tool uses a novel \emph{discriminative local feature projection} mechanism to combine three features into a single weight for each edge (details in Section~\ref{subsubsec:weight-computation}). 

The second key insight of \tool is that a file is very likely to contain malicious payloads if it is created by a malicious file or comes from a malicious website.
On the other hand, a file can be trusted if it is created by official installation files (\eg official Microsoft installation packages and Google updater) or other trusted sources. 

Based on this insight, \tool assigns seed nodes with initial reputations and propagates the reputations from the seed nodes to all other nodes.
Seed nodes are usually trusted sources like Chrome updater (assigned with high reputations), system libraries like libc (assigned with neutral reputations), or unknown sources like USB sticks or malicious websites (assigned with low reputations). 
A node in the dependency graph receives its reputation by aggregating the weighted reputations from all of its parent nodes.
% To ensure each node's reputation would not exceed the maximum reputation of its parent nodes, \tool further normalizes the weights of the incoming edges for a node.
The propagation process is an iterative process and repeats until the reputation of all the nodes become stable.



We evaluate \tool by constructing 21 cases from operations that employ key system interfaces (11 cases) and five real APT attack scenarios (10 cases)
Our graph reduction results show that \tool is able to effectively reduce up to 72.8\% nodes and 97.4\% edges in the original dependency graph, thanks to its causality reduction and edge merge components. We also show that with the help of weighted dependency graph produced by \tool, security analysts are able to effectively surface critical edges from non-critical edges by controlling the threshold on filtering edge weights.
Our reputation propagation results show that \tool is able to accurately propagate the reputation from trusted seeds in both high initial seed reputation setting (\emph{HighRP}) and low initial seed reputation setting (\emph{LowRP}), thanks to its novel weight computation mechanism.
Compared to the baseline approaches, the local cluster and projection approach employed by \tool achieves the best performance for most of the cases in both \emph{HighRP} setting and \emph{LowRP} setting. 
Specifically, \tool achieves up to 22\% average percentage improvement in \emph{HighRP} setting and 92\% average percentage improvement in \emph{LowRP} setting.




Below are the main contributions of \tool:
\begin{itemize}
\item \tool is a novel causality analysis approach that addresses the shortcomings of the existing approaches. 
    \begin{itemize}
     \item \tool extracts the features from the system call event, and hence it does not require changes of end-user system.
    \item \tool leverages the differences of the extracted features to compute weights for distinguishing critical and non-critical edges, and it does not need a reference model of normal activities.
    \item \tool hides non-critical edges with low weights, and thus does not use heuristics that can cause a loss of dependencies for certain entities.
    \end{itemize}
\item \tool provides reputation propagation to automate the inspection of the dependency graph, which has limited support from the existing approaches.
    \item \tool is evaluated on representative cases for key system interfaces that are vulnerable for attacks and real APT attacks, and the results demonstrate the effectiveness of \tool in addressing dependency explosion and propagating reputation.
\end{itemize}