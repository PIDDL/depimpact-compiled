
\input{tables/attacksLowRP.tex}

\subsubsection{Reputation Propagation}
\label{subsec:reputation-results}
We evaluate the effectiveness of \tool in identifying whether POI entities come from trusted sources or suspicious sources via reputation propagation in both normal and malicious scenarios, respectively.

\myparatight{Evaluation Setup}
All the nodes that have no incoming edges are considered as seed nodes.
We set the reputation of seed nodes representing trusted sources to $1.0$,
and seed nodes representing system libraries to $0.5$.
In malicious scenarios and APT attacks, we set the reputation of seed nodes representing suspicious sources to $0.0$.
We propagate the reputation from seed nodes according to \cref{alg:reputaionPropagation},
and record the reputation scores of the POI entities (referred to as \emph{POI reputation}).
An effective approach will lead to a higher POI reputation in the benign scenarios and a lower POI reputation in the malicious scenarios.

To demonstrate the effectiveness of \tool's weight computation, we compare the POI reputations computed by the following four weight computation approaches:
\begin{itemize}[noitemsep, topsep=1pt, partopsep=1pt, listparindent=\parindent, leftmargin=*]
    
    \item \lpfixed: We select a fixed parameter vector $(0.1, 0.5, 0.4)$ empirically and normalize it to be the projection vector.
    
    \item \lpglobal: We globally cluster all edges in the graph using Multi-KMeans++ and compute the projection vector using extended LDA. 
    
    \item \lpglobalplus: Same as previous one, but for nodes that have only one incoming edge (\ie outlier edges), we do not consider these edges in the global clustering and global projection vector computation, and directly assign their final weights to 1.

    \item \tool: This is the one described in \cref{subsec:weight-computation}. We locally cluster the incoming edges of every node using Multi-KMeans++ and locally compute the projection vector using extended LDA.
    
\end{itemize}

Furthermore, we compare our weight computation approach with the 
%edge 
event priority computation used in the state-of-the-art causality analysis approach, PrioTracker~\cite{liu2018priotracker}.
PrioTracker mainly uses the fanout of nodes to prioritize the dependencies in the causality analysis for a given POI event.
While they also use a rareness score based on the reference models built upon normal activities in their proprietary environment, their models are not publicly available and difficult to generalize from their organizations to our deployed environment.
Given that the rareness score accounts for only a small portion of their priority (\ie 27\%), we use only the fanout of nodes to compute edge priories.\footnote{Note that the reference models are complementary to \tool, and \tool can easily integrate the rareness score with our weights to compute to final edge weights.}
We then adapt the computed priories as the edge weights, and apply our algorithm for reputation propagation.
In this way, we can do a fair comparison between \tool and PrioTracker in reputation propagation.


\cref{tab:benignHighRP,tab:benignLowRP} show the results for benign and malicious payloads through key system interfaces.
\cref{tab:attackLowRP} shows the results for the APT attacks.

\eat{
\myparatight{Evaluation Metric}
A better approach will lead to a higher POI reputation in the benign scenarios and a lower POI reputation in the malicious scenarios.
We compare the \emph{average percentage improvement} of POI reputations of \lpfixed, \lpglobal, \lpglobalplus, and \tool.
% Specifically, in the benign scenarios, the percentage improvement is computed as $\frac{RP - RP_{\lpfixed}}{RP_{\lpfixed}}$. In the malicious scenarios, the percentage improvement is calculated as $\frac{RP_{\lpfixed}-RP}{RP_{\lpfixed}}$.
}

\myparatight{POI Reputations of \tool}
The results show that \tool effectively propagate the reputation scores from trusted and suspicious sources to the POI entities (averagely $0.99$ for benign scenarios and averagely $0.03$ in malicious scenarios).
This indicates the effectiveness of our weight computation (\cref{subsec:weight-computation}) and reputation inheritance (\cref{subsec:attack-investigation}).

\myparatight{Comparisons of Four Weight Computation Approaches}
We have the following observations:
(1) The performance of \lpglobalplus significantly improves over \lpglobal.
This shows the effectiveness and necessity of treating outlier edges differently when doing weight computation. 
(2) \lpfixed performs better than \lpglobal and \lpglobalplus in system tasks through key system interfaces in both benign and malicious scenarios (\cref{tab:benignHighRP} and \cref{tab:benignLowRP}).
This shows that the dependency graph is quite diverse and it is difficult to separate all edges into two discriminative groups.
However, treating the outlier edges differently in \lpglobalplus improves over \lpfixed for APT attacks.
(3) \tool achieves the best performance in most of the cases. Specifically, \tool achieves 34.67\%, 62.82\%, 43.76\% improvement over \lpfixed, \lpglobal, and \lpglobalplus in benign scenarios (\cref{tab:benignHighRP}) and average 94.52\%, 95.61\%, 86.21\% improvement in malicious scenarios (\cref{tab:benignLowRP,tab:attackLowRP}).
The results clearly show the necessity and superiority of clustering and projecting edges locally for each sink node.
Note that this approach also treats outliers locally by directly setting their weights to 1, and thus \tool embraces the merits of \lpglobalplus and achieves the best performance.

\eat{
By employing this scheme to compute weights, \tool effectively identifies whether a POI entity comes from trusted or malicious sources by propagating initial reputation from seeds.
}

\myparatight{Comparison with PrioTracker}
The results show that \tool achieves 57.22\% improvement over PrioTracker in benign scenarios(\cref{tab:benignHighRP}) and average 87.22\% improvement over PrioTracker in malicious scenarios (\cref{tab:benignLowRP,tab:attackLowRP}).
As we can see from \cref{tab:attackLowRP}, while the average POI reputation achieved by PrioTracker is $0.10$, it achieves bad performance for \textit{penetration-c1} ($0.30$), \textit{penetration-c2} ($0.43$), and \textit{password-crack-c1} ($0.25$),
which will incorrectly label the malicious payloads as neutral,
while \tool correctly assigns low POI reputations ($\leq 0.04$) for these attack steps.
These results demonstrate the superiority of \tool's discriminative weight computation over PrioTracker's priority computation.

\eat{
\xiao{XXX} 66.8\% \pfang{: $\frac{1.3467Manual - 0.8072Manual}{0.8072Manual}$ this calculation is based on the average improvement} improvement over the edge priority based on the fanout of nodes. This is calcualted as $\frac{RP_{avg\_LocalProjection} - RP_{avg\_Fanout}}{RP_{avg\_Fanout}}$Compared with the pure edge priority method, \tool also considers time and data information about POI events. The improvement shows the advantage of \tool to process the dependency graph with complex structure. \pfang{need revise}
}
