\subsection{Phase III: Attack Investigation}
\label{subsec:attack-investigation}


\eat{
In this sense, we specify undirected edges that carry out the information of the security event as critical edges for filtering. The threshold is specified as a multiple of average weight of all the edges in the graph (\eg 2 times the average weight). To retain the critical edges, we choose the threshold according to the minimum weight of the undirected critical edges. If there are two edges with different directions connecting the same pair of nodes in the graph, we will use the maximum of their weights for threshold computation and both of them will be kept in the filtered graph. The nodes that are not in the same weakly connected component of the POI event are also removed.}

\myparatight{Reputation Propagation}
\eat{key questions: how to select seed sources; why set to 0/1 for seeds}
\eat{two insights of inheritance fashion: (1) enough reputation gets propagated; (2) child nodes no more rp than parents + reasons why design like this}
% The goal of this part is to provide a numerical method to help security analyst automatically investigate all the potential malicious entities. 
% \subsubsection{Seed Selection}
To perform reputation propagation, \tool assigns initial reputations to seed nodes and propagates the reputations using an inheritance fashion.

\emph{Reputation Scheme}.
The design goal of the reputation scheme is to capture the fact that if a file (or program) is downloaded or installed from a reputable source, it should be more reliable than the file (program) downloaded from an suspicious website or from an suspicious equipment, and the reputation of files (programs) from the reliable sources should be higher than the reputation of those from suspicious sources. As such, we define the reputation of a system entity to be $\lbrack 0.0,1.0 \rbrack$, where a file (program) from trusted sources should have a reputation closer to $1.0$, and a file (program) from suspicious sources should have a reputation closer to $0.0$. 


\emph{Seed Sources and System Libraries}.
Seed nodes are the nodes without incoming edges in the dependency graph. They are usually trusted sources such as official updates like Microsoft updater or Chrome updater (assigned high reputations), system libraries like libc (assigned neutral reputations), or suspicious sources like USB sticks or malicious websites (assigned with low reputations). For each trusted seed, its initial reputation is set to $1.0$; for each suspicious seed, its initial reputation is set to $0.0$. 
Additionally, since the system libraries will be used by both legitimate users and attackers, we cannot easily infer a node's nature from its correlations with the system libraries. Thus, the initial reputations of seed nodes representing system packages are set to $0.5$.

\emph{Reputation Inheritance}.
Based on the edge weights and the chosen seeds, we iteratively update other nodes' reputation values. 
To prevent fast degradation of reputation values, \tool updates a node's reputation using an inheritance fashion:  
\begin{equation}
    \label{eq:reputation}
     R_{v} =\sum_{e \in IncomingEdge(v)} R_{sourceNode(e)}*W_e,
\end{equation}
where $IncomingEdge(v)$ represents the set of incoming edges of $v$, $sourceNode(e)$ represents the source node of $e$, $R_{sourceNode(e)}$ represents the reputation of $sourceNode(e)$, and $W_e$ represents the weight of $e$.


\input{ReputationPropagationPseudo.tex}

\cref{alg:reputaionPropagation} gives the details of reputation propagation. 
A node $v$ in the dependency graph receives its reputation by inheriting the weighted reputations from all of its parent nodes (Lines 7-11).
Note that if we adopt a distribution fashion that ensures the sum of reputations for $v$'s children nodes to be equal to $v$'s reputation,
then the reputation will degrade quickly in a few hops, which does not work well for dependency graphs that often have many paths with many hops.
%
The process of reputation propagation is an iterative process.
For each iteration, the algorithm computes the sum of reputation differences for all the nodes (Line 13).
The propagation terminates when the aggregate difference between the current iteration and the previous iteration is smaller than a threshold $\delta$ (Line 1), indicating that the reputations for all nodes become stable.
Empirically, we set $\delta = 1e-13$.
%$\delta = 1.0E-13 $.
Note that the reputations of the seed nodes remain unchanged (Lines 4-6).


\myparatight{Attack Sequence Reconstruction}
\tool leverages the weights in the dependency graph for reconstructing the attack sequence, which consists of critical edges and their nodes.
Since the weights computed by \tool aim to maximize the difference between critical and non-critical edges, we can specify a minimum weight as a threshold and hide the edges with weights below that threshold.
For example, the weights of edges from the irrelevant system activities (\eg daily tasks or file indexing) usually have lower weights than those representing the attack provenance.
By carefully choosing this threshold, \tool can filter out these irrelevant system activities while retaining the attack provenance (\cref{subsec:graphreduction}).

In practice, security analysts can first hide the non-critical edges using a higher threshold to focus on the investigation of the attack, and gradually show part of the non-critical edges by lowering the threshold to get more context of the attack-related activities.
For example, certain system libraries may reveal the functionality that the malicious payloads possess.  
\eat{
Based on our results in , choosing the threshold within $\lbrack 0.1,0.25 \rbrack$ can prune most of the non-critical edges while retain the critical edges.} 



\eat{

 Even after Edge Merge, there are often a large portion of relevant yet non-critical nodes and edges, such as Python run-time dependencies, dynamic linking libraries, and Linux configuration files. These elements make the graph still too messy to be interpreted by security analysts. 

 Given that the weight distribution is different for each dependency graph, \tool uses a threshold value computed using $T_w * W_{avg}$, where $W_{avg}$ represents the average weights in the dependency graph.

}